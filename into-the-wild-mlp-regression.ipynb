{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from contextlib import contextmanager\n",
    "import gc\n",
    "import os\n",
    "import psutil\n",
    "import time\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from tsfresh.feature_extraction import feature_calculators\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "import scipy as sp\n",
    "import itertools\n",
    "import warnings\n",
    "# import librosa\n",
    "import pywt\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import signal\n",
    "from keras.models import Model\n",
    "import keras.layers as L\n",
    "from sklearn import preprocessing\n",
    "def normalize(X_train, X_test, normalize_opt, feats):\n",
    "    if normalize_opt != None:\n",
    "        if normalize_opt == 'min_max':\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "        elif normalize_opt == 'robust':\n",
    "            scaler = preprocessing.RobustScaler()\n",
    "        elif normalize_opt == 'standard':\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "        elif normalize_opt == 'max_abs':\n",
    "            scaler = preprocessing.MaxAbsScaler()\n",
    "        scaler = scaler.fit(X_train[feats])\n",
    "        X_train[feats] = scaler.transform(X_train[feats])\n",
    "        X_test[feats] = scaler.transform(X_test[feats])\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df,verbose=True):\n",
    "    \n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if (c_min > np.iinfo(np.int8).min\n",
    "                        and c_max < np.iinfo(np.int8).max):\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif (c_min > np.iinfo(np.int16).min\n",
    "                      and c_max < np.iinfo(np.int16).max):\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif (c_min > np.iinfo(np.int32).min\n",
    "                      and c_max < np.iinfo(np.int32).max):\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif (c_min > np.iinfo(np.int64).min\n",
    "                      and c_max < np.iinfo(np.int64).max):\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (c_min > np.finfo(np.float32).min\n",
    "                      and c_max < np.finfo(np.float32).max):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    reduction = (start_mem - end_mem) / start_mem\n",
    "\n",
    "    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n",
    "    if verbose:\n",
    "        print(msg)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(title, new_line=True):\n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how=\"left\", on=\"SK_ID_CURR\")\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f\"{title} - done in {time.time() - t0:.0f}s\")\n",
    "    if new_line:\n",
    "        print()\n",
    "        \n",
    "        \n",
    "def report_process_mem_usage():\n",
    "    \"\"\"\n",
    "    Print memory usage (in GB) of main process\n",
    "    \"\"\"\n",
    "    print(f\"Main process memory usage: \"\n",
    "          f\"{psutil.Process(os.getpid()).memory_info().rss/1024**3:.2f} GB\")\n",
    " \n",
    "\n",
    "\n",
    "   \n",
    "def evaluate_macroF1(data_vali, preds):  \n",
    "    labels = data_vali.astype(int)\n",
    "    preds = np.array(preds)\n",
    "    preds = np.argmax(preds,axis=1)\n",
    "    score_vali = f1_score(y_true=labels,y_pred=preds,average='macro')\n",
    "    return  score_vali\n",
    "\n",
    "def get_class_weight(classes, exp=1):\n",
    "    '''\n",
    "    Weight of the class is inversely proportional to the population of the class.\n",
    "    There is an exponent for adding more weight.\n",
    "    '''\n",
    "    hist, _ = np.histogram(classes, bins=np.arange(12)-0.5)\n",
    "    class_weight = hist.sum()/np.power(hist, exp)\n",
    "    \n",
    "    return class_weight\n",
    "    \n",
    "\n",
    "    \n",
    "def create_mpl(shape):\n",
    "    '''\n",
    "    Returns a keras model\n",
    "    '''\n",
    "    \n",
    "    X_input = L.Input(shape)\n",
    "    \n",
    "    X = L.Dense(150, activation='relu')(X_input)\n",
    "    X = L.Dense(150, activation='relu')(X)\n",
    "    X = L.Dense(125, activation='relu')(X)\n",
    "    X = L.Dense(75, activation='relu')(X)\n",
    "    X = L.Dense(50, activation='relu')(X)\n",
    "    X = L.Dense(25, activation='relu')(X)\n",
    "    X = L.Dense(1)(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_gradients(s, n_grads=4):\n",
    "    '''\n",
    "    Calculate gradients for a pandas series. Returns the same number of samples\n",
    "    '''\n",
    "    grads = pd.DataFrame()\n",
    "    \n",
    "    g = s.values\n",
    "    for i in range(n_grads):\n",
    "        g = np.gradient(g)\n",
    "        grads['grad_' + str(i+1)] = g\n",
    "        \n",
    "    return grads\n",
    "\n",
    "\n",
    "def calc_low_pass(s, n_filts=10):\n",
    "    '''\n",
    "    Applies low pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.3, n_filts)\n",
    "    \n",
    "    low_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='low')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        low_pass['lowpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        low_pass['lowpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return low_pass\n",
    "\n",
    "\n",
    "def calc_high_pass(s, n_filts=10):\n",
    "    '''\n",
    "    Applies high pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.1, n_filts)\n",
    "    \n",
    "    high_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='high')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        high_pass['highpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        high_pass['highpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return high_pass\n",
    "\n",
    "\n",
    "def calc_roll_stats(s, windows=[10, 50, 100, 500, 1000]):\n",
    "    '''\n",
    "    Calculates rolling stats like mean, std, min, max...\n",
    "    '''\n",
    "    roll_stats = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        roll_stats['roll_mean_' + str(w)] = s.rolling(window=w, min_periods=1).mean()\n",
    "        roll_stats['roll_std_' + str(w)] = s.rolling(window=w, min_periods=1).std()\n",
    "        roll_stats['roll_min_' + str(w)] = s.rolling(window=w, min_periods=1).min()\n",
    "        roll_stats['roll_max_' + str(w)] = s.rolling(window=w, min_periods=1).max()\n",
    "        roll_stats['roll_range_' + str(w)] = roll_stats['roll_max_' + str(w)] - roll_stats['roll_min_' + str(w)]\n",
    "        roll_stats['roll_q10_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.10)\n",
    "        roll_stats['roll_q25_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.25)\n",
    "        roll_stats['roll_q50_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.50)\n",
    "        roll_stats['roll_q75_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.75)\n",
    "        roll_stats['roll_q90_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.90)\n",
    "    \n",
    "    # add zeros when na values (std)\n",
    "    roll_stats = roll_stats.fillna(value=0)\n",
    "             \n",
    "    return roll_stats\n",
    "\n",
    "def calc_ewm(s, windows=[10, 50, 100, 500, 1000]):\n",
    "    '''\n",
    "    Calculates exponential weighted functions\n",
    "    '''\n",
    "    ewm = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        ewm['ewm_mean_' + str(w)] = s.ewm(span=w, min_periods=1).mean()\n",
    "        ewm['ewm_std_' + str(w)] = s.ewm(span=w, min_periods=1).std()\n",
    "        \n",
    "    # add zeros when na values (std)\n",
    "    ewm = ewm.fillna(value=0)\n",
    "        \n",
    "    return ewm\n",
    "\n",
    "\n",
    "def add_features(s):\n",
    "    '''\n",
    "    All calculations together\n",
    "    '''\n",
    "    \n",
    "    # gradients = calc_gradients(s)\n",
    "    # low_pass = calc_low_pass(s)\n",
    "    high_pass = calc_high_pass(s)\n",
    "    roll_stats = calc_roll_stats(s)\n",
    "    ewm = calc_ewm(s)\n",
    "    temp=pd.concat([s, high_pass, roll_stats, ewm], axis=1)\n",
    "    return temp\n",
    "\n",
    "\n",
    "def divide_and_add_features(s, signal_size=100000):\n",
    "    '''\n",
    "    Divide the signal in bags of \"signal_size\".\n",
    "    Normalize the data dividing it by 15.0\n",
    "    '''\n",
    "    # normalize\n",
    "    # s = s/15.0\n",
    "    \n",
    "    ls = []\n",
    "    for i in tqdm(range(int(s.shape[0]/signal_size))):\n",
    "        sig = s[i*signal_size:(i+1)*signal_size].copy().reset_index(drop=True)\n",
    "        sig_featured = add_features(sig)\n",
    "        ls.append(sig_featured)\n",
    "\n",
    "    return pd.concat(ls, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "SEED = 321\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main process memory usage: 0.53 GB\n",
      "Load saved features from disk - done in 4s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Load saved features from disk\"):\n",
    "    submission  = pd.read_csv('/kaggle/input/liverpool-ion-switching/sample_submission.csv') \n",
    "    train = pd.read_csv(\"/kaggle/input/remove-trends-giba/train_clean_giba.csv\", usecols=[\"signal\",\"open_channels\"], dtype={'signal': np.float32, 'open_channels':np.int32})\n",
    "    test  = pd.read_csv(\"/kaggle/input/remove-trends-giba/test_clean_giba.csv\", usecols=[\"signal\"], dtype={'signal': np.float32})\n",
    "\n",
    "    # 5+8 Augmentation to Create new batch with 10 channels\n",
    "    train['group'] = np.arange(train.shape[0])//500_000\n",
    "    aug_df = train[train[\"group\"] == 5].copy()\n",
    "    aug_df[\"group\"] = 10\n",
    "\n",
    "    for col in [\"signal\", \"open_channels\"]:\n",
    "        aug_df[col] += train[train[\"group\"] == 8][col].values\n",
    "\n",
    "    train = train.append(aug_df, sort=False).reset_index(drop=True)\n",
    "    del aug_df\n",
    "\n",
    "    y=train['open_channels']\n",
    "    del train['open_channels']\n",
    "    gc.collect()\n",
    "\n",
    "    report_process_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal\n"
     ]
    }
   ],
   "source": [
    "for item in ['signal']:\n",
    "    if item in train.columns:\n",
    "        print(item)\n",
    "        train_input_mean = train[item].mean()\n",
    "        train_input_sigma = train[item].std()\n",
    "        train[item]= (train[item] - train_input_mean) / train_input_sigma\n",
    "        test[item] = (test[item] - train_input_mean) / train_input_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166caf26b06842388d76bb61a2fd1ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=55.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d169e7a70e040faab80b2a7a9420b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "public features - done in 160s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with timer(\"public features\"): \n",
    "    train= divide_and_add_features(train['signal'],signal_size=100_000)\n",
    "    test= divide_and_add_features(test['signal'],signal_size=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, (4400000, 81), (1100000, 81)\n",
      "(81,)\n",
      "Epoch 1/50\n",
      "4400000/4400000 [==============================] - 91s 21us/step - loss: 0.0469\n",
      "Epoch 2/50\n",
      "4400000/4400000 [==============================] - 92s 21us/step - loss: 0.0335\n",
      "Epoch 3/50\n",
      "4400000/4400000 [==============================] - 94s 21us/step - loss: 0.0324\n",
      "Epoch 4/50\n",
      "4400000/4400000 [==============================] - 93s 21us/step - loss: 0.0316\n",
      "Epoch 5/50\n",
      "4400000/4400000 [==============================] - 91s 21us/step - loss: 0.0312\n",
      "Epoch 6/50\n",
      "4400000/4400000 [==============================] - 92s 21us/step - loss: 0.0309\n",
      "Epoch 7/50\n",
      "4400000/4400000 [==============================] - 89s 20us/step - loss: 0.0306\n",
      "Epoch 8/50\n",
      "4400000/4400000 [==============================] - 88s 20us/step - loss: 0.0283\n",
      "Epoch 43/50\n",
      "4400000/4400000 [==============================] - 87s 20us/step - loss: 0.0283\n",
      "Epoch 44/50\n",
      "4400000/4400000 [==============================] - 90s 20us/step - loss: 0.0303\n",
      "Epoch 9/50\n",
      "4400000/4400000 [==============================] - 88s 20us/step - loss: 0.0287\n",
      "Epoch 21/50\n",
      "4400000/4400000 [==============================] - 89s 20us/step - loss: 0.0287\n",
      "Epoch 22/50\n",
      "4400000/4400000 [==============================] - 91s 21us/step - loss: 0.0301\n",
      "Epoch 10/50\n",
      "4400000/4400000 [==============================] - 89s 20us/step - loss: 0.0300\n",
      "Epoch 11/50\n",
      "4400000/4400000 [==============================] - 87s 20us/step - loss: 0.0304\n",
      "Epoch 10/50\n",
      "4400000/4400000 [==============================] - 87s 20us/step - loss: 0.0296\n",
      "Epoch 16/50\n",
      "4400000/4400000 [==============================] - 87s 20us/step - loss: 0.0287\n",
      "Epoch 28/50\n",
      "4400000/4400000 [==============================] - 88s 20us/step - loss: 0.0308\n",
      "Epoch 11/50\n",
      "4400000/4400000 [==============================] - 88s 20us/step - loss: 0.0307\n",
      "Epoch 12/50\n",
      "4400000/4400000 [==============================] - 89s 20us/step - loss: 0.0281\n",
      "Epoch 45/50\n",
      "4399360/4400000 [============================>.] - ETA: 0s - loss: 0.0280"
     ]
    }
   ],
   "source": [
    "n_splits=5    \n",
    "remove_fea=['time','batch','batch_index','batch_slices','batch_slices2','group']\n",
    "features=[i for i in train.columns if i not in remove_fea]\n",
    "\n",
    "with timer(\"train lgb model:\"):\n",
    "    cv_result = []\n",
    "    cv_pred = []\n",
    "    oof_preds = np.zeros(train.shape[0])\n",
    "    y_preds = np.zeros(test.shape[0]) \n",
    "\n",
    "    target = \"open_channels\"\n",
    "    train['group'] = np.arange(train.shape[0])//4000\n",
    "    group = train['group']\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    splits = [x for x in kf.split(train, y, group)]\n",
    "\n",
    "    for fold, (tr_ind, val_ind) in enumerate(splits):\n",
    "        x_train, x_val = train[features].iloc[tr_ind].values, train[features].iloc[val_ind].values\n",
    "        y_train, y_val = y[tr_ind].values, y[val_ind].values\n",
    "        print(f'Fold {fold + 1}, {x_train.shape}, {x_val.shape}')\n",
    "        class_weight = get_class_weight(y_train)\n",
    "        print(x_train[0].shape)\n",
    "        #weight=class_weight[y_train]\n",
    "        mlp = create_mpl(x_train[0].shape)\n",
    "        mlp.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        mlp.fit(x=x_train, y=y_train, epochs=50, batch_size=256, class_weight=class_weight, verbose = 1)  \n",
    "        del x_train,y_train\n",
    "        gc.collect()\n",
    "        oof_preds[val_ind] = mlp.predict(x_val).reshape(x_val.shape[0],)\n",
    "        del x_val\n",
    "        gc.collect()\n",
    "        result = f1_score(y_val,np.round(np.clip(oof_preds[val_ind], 0, 10)).astype(int),average='macro')\n",
    "        print('f1 score : ',result)\n",
    "        cv_result.append(round(result,5))\n",
    "        y_preds += mlp.predict(test[features]).reshape(test.shape[0],)/n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9373082574382354"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y,np.round(np.clip(oof_preds, 0, 10)).astype(int),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383893669242258"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y[:5000_000],np.round(np.clip(oof_preds[:5000_000], 0, 10)).astype(int),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('mlp_reg.npz',valid=oof_preds, test=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93865, 0.93539, 0.93865, 0.93838, 0.93537]\n",
      "[CV] F1 Mean: 0.937288\n",
      "[CV] F1 Std: 0.0015610048046050054\n"
     ]
    }
   ],
   "source": [
    "# report OOF RMSE and QWK\n",
    "print(cv_result)\n",
    "f1_mean,f1_std = np.mean(cv_result),np.std(cv_result)\n",
    "print(f\"[CV] F1 Mean: {f1_mean}\")\n",
    "print(f\"[CV] F1 Std: {f1_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1220707\n",
      "1      216718\n",
      "3      135066\n",
      "2      117215\n",
      "4       80394\n",
      "5       55675\n",
      "7       52921\n",
      "8       49775\n",
      "6       36967\n",
      "9       27536\n",
      "10       7026\n",
      "Name: open_channels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# make test predictions with optimized coefficients\n",
    "sub_preds = np.round(np.clip(y_preds, 0, 10)).astype(int)\n",
    "submission['open_channels'] = sub_preds\n",
    "print(submission['open_channels'].value_counts()) \n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "062dd178c3c04ab0b68ebe6f1b25be05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d7ca730f6924d91a71a5f3086fa9447": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "166caf26b06842388d76bb61a2fd1ded": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3248398820494bb18c4a1952291fe44d",
        "IPY_MODEL_e23f66d97750491faf8000d1a0bf84b0"
       ],
       "layout": "IPY_MODEL_cba86ad191204cdb9a750b03ad8dcd9f"
      }
     },
     "1efe23f6dfb146bea27a59bfdf61ffd6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2aff3f0980734dcd94a0d721bee8a768": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2ff4e86fb0c44f72a2b7862fcccf6509": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "3248398820494bb18c4a1952291fe44d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0d7ca730f6924d91a71a5f3086fa9447",
       "max": 55.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c887e8265c4e4840a28a91c572592c65",
       "value": 55.0
      }
     },
     "4d0c8c0cc61c43ee8bb7a8f1eb7dfcaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a83485ba0fd64f25884904b02b459182",
       "placeholder": "​",
       "style": "IPY_MODEL_6f6b9572321d423491d3b01a70b64c0c",
       "value": " 20/20 [00:49&lt;00:00,  2.45s/it]"
      }
     },
     "6d169e7a70e040faab80b2a7a9420b14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dd4be60461be45969b764513b1d6e3de",
        "IPY_MODEL_4d0c8c0cc61c43ee8bb7a8f1eb7dfcaa"
       ],
       "layout": "IPY_MODEL_1efe23f6dfb146bea27a59bfdf61ffd6"
      }
     },
     "6f6b9572321d423491d3b01a70b64c0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a83485ba0fd64f25884904b02b459182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c887e8265c4e4840a28a91c572592c65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "cba86ad191204cdb9a750b03ad8dcd9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd4be60461be45969b764513b1d6e3de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_062dd178c3c04ab0b68ebe6f1b25be05",
       "max": 20.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2ff4e86fb0c44f72a2b7862fcccf6509",
       "value": 20.0
      }
     },
     "e23f66d97750491faf8000d1a0bf84b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e4fc806c779a48689ecbe11f80f52e59",
       "placeholder": "​",
       "style": "IPY_MODEL_2aff3f0980734dcd94a0d721bee8a768",
       "value": " 55/55 [01:52&lt;00:00,  2.05s/it]"
      }
     },
     "e4fc806c779a48689ecbe11f80f52e59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

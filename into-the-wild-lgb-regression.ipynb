{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from collections import Counter\n",
    "from contextlib import contextmanager\n",
    "import gc\n",
    "import os\n",
    "import psutil\n",
    "import time\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from tsfresh.feature_extraction import feature_calculators\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "import scipy as sp\n",
    "import itertools\n",
    "import warnings\n",
    "import pywt\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import check_cv\n",
    "\n",
    "from category_encoders import CatBoostEncoder\n",
    "\n",
    "def reduce_mem_usage(df,verbose=True):\n",
    "    \n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if (c_min > np.iinfo(np.int8).min\n",
    "                        and c_max < np.iinfo(np.int8).max):\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif (c_min > np.iinfo(np.int16).min\n",
    "                      and c_max < np.iinfo(np.int16).max):\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif (c_min > np.iinfo(np.int32).min\n",
    "                      and c_max < np.iinfo(np.int32).max):\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif (c_min > np.iinfo(np.int64).min\n",
    "                      and c_max < np.iinfo(np.int64).max):\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (c_min > np.finfo(np.float32).min\n",
    "                      and c_max < np.finfo(np.float32).max):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    reduction = (start_mem - end_mem) / start_mem\n",
    "\n",
    "    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n",
    "    if verbose:\n",
    "        print(msg)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500000, 5)\n"
     ]
    }
   ],
   "source": [
    "submission  = pd.read_csv('/kaggle/input/liverpool-ion-switching/sample_submission.csv') \n",
    "train = pd.read_csv('/kaggle/input/remove-trends-giba/train_clean_giba.csv')\n",
    "test  = pd.read_csv('/kaggle/input/remove-trends-giba/test_clean_giba.csv')\n",
    "del train[\"type\"], test[\"type\"]\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "train[\"category\"] = 0\n",
    "test[\"category\"] = 0\n",
    "\n",
    "# train segments with more then 9 open channels classes\n",
    "train.loc[2_000_000:2_500_000, 'category'] = 1\n",
    "train.loc[4_500_000:5_000_000, 'category'] = 1\n",
    "\n",
    "# test segments with more then 9 open channels classes (potentially)\n",
    "test.loc[500_000:600_000, \"category\"] = 1\n",
    "test.loc[700_000:800_000, \"category\"] = 1\n",
    "\n",
    "train['group'] = np.arange(train.shape[0])//500_000    \n",
    "aug_df = train[train[\"group\"] == 5].copy()\n",
    "aug_df[\"group\"] = 10\n",
    "aug_df[\"category\"] = 1\n",
    "for col in [\"signal\", \"open_channels\"]:\n",
    "    aug_df[col] += train[train[\"group\"] == 8][col].values\n",
    "\n",
    "train = train.append(aug_df, sort=False).reset_index(drop=True)\n",
    "del aug_df\n",
    "gc.collect()\n",
    "\n",
    "y=train['open_channels']\n",
    "\n",
    "# train = reduce_mem_usage(train,verbose=True)\n",
    "# test = reduce_mem_usage(test,verbose=True)\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['batch'] = np.arange(train.shape[0])//100_000\n",
    "test['batch'] = np.arange(test.shape[0])//100_000\n",
    "\n",
    "shift_sizes = np.arange(1,21)\n",
    "for temp in [train,test]:\n",
    "    for shift_size in shift_sizes:    \n",
    "        temp['signal_shift_pos_'+str(shift_size)] = temp.groupby('batch')['signal'].shift(shift_size).fillna(-3)\n",
    "        # temp['signal_shift_pos_'+str(shift_size)] = temp.groupby(\"batch\")['signal_shift_pos_'+str(shift_size)].transform(lambda x: x.bfill())\n",
    "        temp['signal_shift_neg_'+str(shift_size)] = temp.groupby('batch')['signal'].shift(-1*shift_size).fillna(-3)\n",
    "        # temp['signal_shift_neg_'+str(shift_size)] = temp.groupby(\"batch\")['signal_shift_neg_'+str(shift_size)].transform(lambda x: x.ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>category</th>\n",
       "      <th>signal_shift_pos_1</th>\n",
       "      <th>signal_shift_neg_1</th>\n",
       "      <th>signal_shift_pos_2</th>\n",
       "      <th>signal_shift_neg_2</th>\n",
       "      <th>signal_shift_pos_3</th>\n",
       "      <th>signal_shift_neg_3</th>\n",
       "      <th>signal_shift_pos_4</th>\n",
       "      <th>signal_shift_neg_4</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_shift_pos_16</th>\n",
       "      <th>signal_shift_neg_16</th>\n",
       "      <th>signal_shift_pos_17</th>\n",
       "      <th>signal_shift_neg_17</th>\n",
       "      <th>signal_shift_pos_18</th>\n",
       "      <th>signal_shift_neg_18</th>\n",
       "      <th>signal_shift_pos_19</th>\n",
       "      <th>signal_shift_neg_19</th>\n",
       "      <th>signal_shift_pos_20</th>\n",
       "      <th>signal_shift_neg_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.036510</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.113152</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.245390</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.341122</td>\n",
       "      <td>-3.00000</td>\n",
       "      <td>-0.350929</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.170745</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.314478</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.225048</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.385705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.113152</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036510</td>\n",
       "      <td>0.245390</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.341122</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.350929</td>\n",
       "      <td>-3.00000</td>\n",
       "      <td>0.057489</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.314478</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.225048</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.385705</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.270212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245390</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.113152</td>\n",
       "      <td>-0.341122</td>\n",
       "      <td>-0.036510</td>\n",
       "      <td>-0.350929</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.057489</td>\n",
       "      <td>-3.00000</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.314478</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.225048</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.385705</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.270212</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.119530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.341122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245390</td>\n",
       "      <td>-0.350929</td>\n",
       "      <td>-0.113152</td>\n",
       "      <td>0.057489</td>\n",
       "      <td>-0.036510</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>-3.00000</td>\n",
       "      <td>0.095803</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.225048</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.385705</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.270212</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.119530</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.396299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.350929</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.341122</td>\n",
       "      <td>0.057489</td>\n",
       "      <td>0.245390</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>-0.113152</td>\n",
       "      <td>0.095803</td>\n",
       "      <td>-0.03651</td>\n",
       "      <td>0.035858</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.385705</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.270212</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.119530</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.396299</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.119804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     signal  category  signal_shift_pos_1  signal_shift_neg_1  \\\n",
       "0 -0.036510         0           -3.000000           -0.113152   \n",
       "1 -0.113152         0           -0.036510            0.245390   \n",
       "2  0.245390         0           -0.113152           -0.341122   \n",
       "3 -0.341122         0            0.245390           -0.350929   \n",
       "4 -0.350929         0           -0.341122            0.057489   \n",
       "\n",
       "   signal_shift_pos_2  signal_shift_neg_2  signal_shift_pos_3  \\\n",
       "0           -3.000000            0.245390           -3.000000   \n",
       "1           -3.000000           -0.341122           -3.000000   \n",
       "2           -0.036510           -0.350929           -3.000000   \n",
       "3           -0.113152            0.057489           -0.036510   \n",
       "4            0.245390            0.011333           -0.113152   \n",
       "\n",
       "   signal_shift_neg_3  signal_shift_pos_4  signal_shift_neg_4  ...  \\\n",
       "0           -0.341122            -3.00000           -0.350929  ...   \n",
       "1           -0.350929            -3.00000            0.057489  ...   \n",
       "2            0.057489            -3.00000            0.011333  ...   \n",
       "3            0.011333            -3.00000            0.095803  ...   \n",
       "4            0.095803            -0.03651            0.035858  ...   \n",
       "\n",
       "   signal_shift_pos_16  signal_shift_neg_16  signal_shift_pos_17  \\\n",
       "0                 -3.0            -0.170745                 -3.0   \n",
       "1                 -3.0             0.006632                 -3.0   \n",
       "2                 -3.0             0.314478                 -3.0   \n",
       "3                 -3.0            -0.225048                 -3.0   \n",
       "4                 -3.0            -0.385705                 -3.0   \n",
       "\n",
       "   signal_shift_neg_17  signal_shift_pos_18  signal_shift_neg_18  \\\n",
       "0             0.006632                 -3.0             0.314478   \n",
       "1             0.314478                 -3.0            -0.225048   \n",
       "2            -0.225048                 -3.0            -0.385705   \n",
       "3            -0.385705                 -3.0            -0.270212   \n",
       "4            -0.270212                 -3.0            -0.119530   \n",
       "\n",
       "   signal_shift_pos_19  signal_shift_neg_19  signal_shift_pos_20  \\\n",
       "0                 -3.0            -0.225048                 -3.0   \n",
       "1                 -3.0            -0.385705                 -3.0   \n",
       "2                 -3.0            -0.270212                 -3.0   \n",
       "3                 -3.0            -0.119530                 -3.0   \n",
       "4                 -3.0            -0.396299                 -3.0   \n",
       "\n",
       "   signal_shift_neg_20  \n",
       "0            -0.385705  \n",
       "1            -0.270212  \n",
       "2            -0.119530  \n",
       "3            -0.396299  \n",
       "4             0.119804  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_fea=['time','batch','batch_index','batch_slices','batch_slices2','group',\"open_channels\"]\n",
    "features=[i for i in train.columns if i not in remove_fea]\n",
    "print(len(features))\n",
    "train[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, (4400000, 42), (1100000, 42)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.194577\tvalid_1's rmse: 0.196425\n",
      "[200]\ttraining's rmse: 0.170569\tvalid_1's rmse: 0.171975\n",
      "[300]\ttraining's rmse: 0.168031\tvalid_1's rmse: 0.169595\n",
      "[400]\ttraining's rmse: 0.167252\tvalid_1's rmse: 0.169156\n",
      "[500]\ttraining's rmse: 0.166571\tvalid_1's rmse: 0.16884\n",
      "[600]\ttraining's rmse: 0.166064\tvalid_1's rmse: 0.168686\n",
      "[700]\ttraining's rmse: 0.165641\tvalid_1's rmse: 0.168596\n",
      "[800]\ttraining's rmse: 0.165243\tvalid_1's rmse: 0.168528\n",
      "[900]\ttraining's rmse: 0.164894\tvalid_1's rmse: 0.168497\n",
      "[1000]\ttraining's rmse: 0.164532\tvalid_1's rmse: 0.168446\n",
      "[1100]\ttraining's rmse: 0.164196\tvalid_1's rmse: 0.168414\n",
      "[1200]\ttraining's rmse: 0.163858\tvalid_1's rmse: 0.168401\n",
      "[1300]\ttraining's rmse: 0.163554\tvalid_1's rmse: 0.168399\n",
      "[1400]\ttraining's rmse: 0.163257\tvalid_1's rmse: 0.168394\n",
      "[1500]\ttraining's rmse: 0.162944\tvalid_1's rmse: 0.168386\n",
      "[1600]\ttraining's rmse: 0.162638\tvalid_1's rmse: 0.168377\n",
      "[1700]\ttraining's rmse: 0.162322\tvalid_1's rmse: 0.168357\n",
      "[1800]\ttraining's rmse: 0.162031\tvalid_1's rmse: 0.168353\n",
      "[1900]\ttraining's rmse: 0.16172\tvalid_1's rmse: 0.168335\n",
      "[2000]\ttraining's rmse: 0.161426\tvalid_1's rmse: 0.168325\n",
      "[2100]\ttraining's rmse: 0.161116\tvalid_1's rmse: 0.168311\n",
      "[2200]\ttraining's rmse: 0.160813\tvalid_1's rmse: 0.168312\n",
      "Early stopping, best iteration is:\n",
      "[2141]\ttraining's rmse: 0.160989\tvalid_1's rmse: 0.168306\n",
      "f1 score :  0.938656825948297\n",
      "Fold 2, (4400000, 42), (1100000, 42)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.194479\tvalid_1's rmse: 0.196559\n",
      "[200]\ttraining's rmse: 0.170479\tvalid_1's rmse: 0.172467\n",
      "[300]\ttraining's rmse: 0.167923\tvalid_1's rmse: 0.170101\n",
      "[400]\ttraining's rmse: 0.167067\tvalid_1's rmse: 0.169579\n",
      "[500]\ttraining's rmse: 0.16646\tvalid_1's rmse: 0.169333\n",
      "[600]\ttraining's rmse: 0.165955\tvalid_1's rmse: 0.169155\n",
      "[700]\ttraining's rmse: 0.165526\tvalid_1's rmse: 0.169061\n",
      "[800]\ttraining's rmse: 0.165157\tvalid_1's rmse: 0.169028\n",
      "[900]\ttraining's rmse: 0.164778\tvalid_1's rmse: 0.168974\n",
      "[1000]\ttraining's rmse: 0.164431\tvalid_1's rmse: 0.168934\n",
      "[1100]\ttraining's rmse: 0.164075\tvalid_1's rmse: 0.1689\n",
      "[1200]\ttraining's rmse: 0.163725\tvalid_1's rmse: 0.168861\n",
      "[1300]\ttraining's rmse: 0.16339\tvalid_1's rmse: 0.168846\n",
      "[1400]\ttraining's rmse: 0.163079\tvalid_1's rmse: 0.168837\n",
      "[1500]\ttraining's rmse: 0.162746\tvalid_1's rmse: 0.168815\n",
      "[1600]\ttraining's rmse: 0.162442\tvalid_1's rmse: 0.168793\n",
      "Early stopping, best iteration is:\n",
      "[1557]\ttraining's rmse: 0.162569\tvalid_1's rmse: 0.16879\n",
      "f1 score :  0.9383035980290724\n",
      "Fold 3, (4400000, 42), (1100000, 42)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.195255\tvalid_1's rmse: 0.193275\n",
      "[200]\ttraining's rmse: 0.171192\tvalid_1's rmse: 0.169355\n",
      "[300]\ttraining's rmse: 0.168645\tvalid_1's rmse: 0.167\n",
      "[400]\ttraining's rmse: 0.167828\tvalid_1's rmse: 0.166493\n",
      "[500]\ttraining's rmse: 0.167198\tvalid_1's rmse: 0.166187\n",
      "[600]\ttraining's rmse: 0.16672\tvalid_1's rmse: 0.166054\n",
      "[700]\ttraining's rmse: 0.16627\tvalid_1's rmse: 0.165959\n",
      "[800]\ttraining's rmse: 0.165892\tvalid_1's rmse: 0.165899\n",
      "[900]\ttraining's rmse: 0.165549\tvalid_1's rmse: 0.165874\n",
      "[1000]\ttraining's rmse: 0.165204\tvalid_1's rmse: 0.165834\n",
      "[1100]\ttraining's rmse: 0.164864\tvalid_1's rmse: 0.165804\n",
      "[1200]\ttraining's rmse: 0.164528\tvalid_1's rmse: 0.165785\n",
      "[1300]\ttraining's rmse: 0.164159\tvalid_1's rmse: 0.165731\n",
      "[1400]\ttraining's rmse: 0.163859\tvalid_1's rmse: 0.165724\n",
      "[1500]\ttraining's rmse: 0.163523\tvalid_1's rmse: 0.165687\n",
      "[1600]\ttraining's rmse: 0.163234\tvalid_1's rmse: 0.165681\n",
      "[1700]\ttraining's rmse: 0.162933\tvalid_1's rmse: 0.165665\n",
      "[1800]\ttraining's rmse: 0.162631\tvalid_1's rmse: 0.165653\n",
      "[1900]\ttraining's rmse: 0.162325\tvalid_1's rmse: 0.165639\n",
      "[2000]\ttraining's rmse: 0.162033\tvalid_1's rmse: 0.165636\n",
      "Early stopping, best iteration is:\n",
      "[1948]\ttraining's rmse: 0.162181\tvalid_1's rmse: 0.16563\n",
      "f1 score :  0.9383576603453784\n",
      "Fold 4, (4400000, 42), (1100000, 42)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.195081\tvalid_1's rmse: 0.193489\n",
      "[200]\ttraining's rmse: 0.170937\tvalid_1's rmse: 0.170291\n",
      "[300]\ttraining's rmse: 0.168449\tvalid_1's rmse: 0.168075\n",
      "[400]\ttraining's rmse: 0.167611\tvalid_1's rmse: 0.167569\n",
      "[500]\ttraining's rmse: 0.166999\tvalid_1's rmse: 0.167286\n",
      "[600]\ttraining's rmse: 0.16654\tvalid_1's rmse: 0.167164\n",
      "[700]\ttraining's rmse: 0.166101\tvalid_1's rmse: 0.167041\n",
      "[800]\ttraining's rmse: 0.165716\tvalid_1's rmse: 0.16698\n",
      "[900]\ttraining's rmse: 0.16536\tvalid_1's rmse: 0.166938\n",
      "[1000]\ttraining's rmse: 0.165044\tvalid_1's rmse: 0.166906\n",
      "[1100]\ttraining's rmse: 0.164699\tvalid_1's rmse: 0.166878\n",
      "[1200]\ttraining's rmse: 0.164377\tvalid_1's rmse: 0.166868\n",
      "[1300]\ttraining's rmse: 0.164049\tvalid_1's rmse: 0.166847\n",
      "[1400]\ttraining's rmse: 0.163729\tvalid_1's rmse: 0.166822\n",
      "[1500]\ttraining's rmse: 0.163387\tvalid_1's rmse: 0.166776\n",
      "[1600]\ttraining's rmse: 0.163074\tvalid_1's rmse: 0.166769\n",
      "[1700]\ttraining's rmse: 0.16276\tvalid_1's rmse: 0.166762\n",
      "[1800]\ttraining's rmse: 0.162456\tvalid_1's rmse: 0.166743\n",
      "[1900]\ttraining's rmse: 0.16215\tvalid_1's rmse: 0.166734\n",
      "[2000]\ttraining's rmse: 0.161837\tvalid_1's rmse: 0.166713\n",
      "[2100]\ttraining's rmse: 0.161533\tvalid_1's rmse: 0.166698\n",
      "[2200]\ttraining's rmse: 0.161225\tvalid_1's rmse: 0.166685\n",
      "[2300]\ttraining's rmse: 0.160933\tvalid_1's rmse: 0.16667\n",
      "[2400]\ttraining's rmse: 0.160636\tvalid_1's rmse: 0.166656\n",
      "[2500]\ttraining's rmse: 0.160345\tvalid_1's rmse: 0.166649\n",
      "[2600]\ttraining's rmse: 0.160045\tvalid_1's rmse: 0.166635\n",
      "[2700]\ttraining's rmse: 0.159764\tvalid_1's rmse: 0.166623\n",
      "[2800]\ttraining's rmse: 0.159484\tvalid_1's rmse: 0.166618\n",
      "Early stopping, best iteration is:\n",
      "[2783]\ttraining's rmse: 0.15953\tvalid_1's rmse: 0.166616\n",
      "f1 score :  0.938960254078346\n",
      "Fold 5, (4400000, 42), (1100000, 42)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.194648\tvalid_1's rmse: 0.19605\n",
      "[200]\ttraining's rmse: 0.170569\tvalid_1's rmse: 0.172224\n",
      "[300]\ttraining's rmse: 0.167978\tvalid_1's rmse: 0.169929\n",
      "[400]\ttraining's rmse: 0.167116\tvalid_1's rmse: 0.169421\n",
      "[500]\ttraining's rmse: 0.166518\tvalid_1's rmse: 0.169179\n",
      "[600]\ttraining's rmse: 0.166028\tvalid_1's rmse: 0.169045\n",
      "[700]\ttraining's rmse: 0.165595\tvalid_1's rmse: 0.168953\n",
      "[800]\ttraining's rmse: 0.165213\tvalid_1's rmse: 0.168902\n",
      "[900]\ttraining's rmse: 0.164854\tvalid_1's rmse: 0.168861\n",
      "[1000]\ttraining's rmse: 0.164509\tvalid_1's rmse: 0.168822\n",
      "[1100]\ttraining's rmse: 0.164185\tvalid_1's rmse: 0.168795\n",
      "[1200]\ttraining's rmse: 0.163867\tvalid_1's rmse: 0.168779\n",
      "[1300]\ttraining's rmse: 0.163549\tvalid_1's rmse: 0.168776\n",
      "[1400]\ttraining's rmse: 0.163227\tvalid_1's rmse: 0.168758\n",
      "[1500]\ttraining's rmse: 0.162913\tvalid_1's rmse: 0.168745\n",
      "[1600]\ttraining's rmse: 0.162592\tvalid_1's rmse: 0.168732\n",
      "[1700]\ttraining's rmse: 0.162285\tvalid_1's rmse: 0.168718\n",
      "[1800]\ttraining's rmse: 0.161985\tvalid_1's rmse: 0.16871\n",
      "[1900]\ttraining's rmse: 0.161673\tvalid_1's rmse: 0.168683\n",
      "Early stopping, best iteration is:\n",
      "[1871]\ttraining's rmse: 0.161755\tvalid_1's rmse: 0.16868\n",
      "f1 score :  0.9372958254337003\n"
     ]
    }
   ],
   "source": [
    "n_splits=5    \n",
    "cv_result = []\n",
    "cv_pred = []\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "y_preds = np.zeros(test.shape[0])\n",
    "\n",
    "target = \"open_channels\"\n",
    "train['group'] = np.arange(train.shape[0])//4000\n",
    "group = train['group']\n",
    "kf = GroupKFold(n_splits=5)\n",
    "splits = [x for x in kf.split(train, y, group)]\n",
    "\n",
    "for fold, (tr_ind, val_ind) in enumerate(splits):\n",
    "    x_train, x_val = train[features].iloc[tr_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = y[tr_ind], y[val_ind]\n",
    "    print(f'Fold {fold + 1}, {x_train.shape}, {x_val.shape}')\n",
    "    train_set = lgb.Dataset(x_train, y_train)\n",
    "    val_set = lgb.Dataset(x_val, y_val)\n",
    "\n",
    "    params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'bagging_fraction': 0.75,#0.75\n",
    "                'bagging_freq': 5,      #5\n",
    "                'learning_rate': 0.05,\n",
    "                'feature_fraction': 0.5,\n",
    "                'max_depth': -1,\n",
    "                'num_leaves': 64,      #64\n",
    "                \"reg_alpha\": 0.1,\n",
    "                \"reg_lambda\": 10,       #10\n",
    "                'verbose': -1,\n",
    "                'seed':2019\n",
    "                }\n",
    "\n",
    "    model = lgb.train(params, train_set, num_boost_round = 3500, early_stopping_rounds =100, valid_sets=[train_set, val_set],verbose_eval = 100)\n",
    "    del x_train,y_train\n",
    "    gc.collect()\n",
    "    oof_preds[val_ind] = model.predict(x_val,num_iteration=model.best_iteration)\n",
    "    del x_val\n",
    "    gc.collect()\n",
    "    result = f1_score(y_val,np.round(np.clip(oof_preds[val_ind], 0, 10)).astype(int),average='macro')\n",
    "    print('f1 score : ',result)\n",
    "    cv_result.append(round(result,5))\n",
    "    y_preds += model.predict(test[features],num_iteration=model.best_iteration)/n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383707083886137"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y,np.round(np.clip(oof_preds, 0, 10)).astype(int),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393805844108304"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y[:5000_000],np.round(np.clip(oof_preds[:5000_000], 0, 10)).astype(int),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1240047\n",
       "1      985733\n",
       "3      672467\n",
       "2      554279\n",
       "4      417394\n",
       "7      400690\n",
       "8      371319\n",
       "5      320684\n",
       "6      280997\n",
       "9      205391\n",
       "10      50999\n",
       "Name: oof, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"oof\"] = np.round(np.clip(oof_preds, 0, 10)).astype(int)\n",
    "train[\"oof\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] F1 Mean: 0.938316\n",
      "[CV] F1 Std: 0.0005599142791535162\n",
      "0     1220702\n",
      "1      216520\n",
      "3      135029\n",
      "2      117443\n",
      "4       80445\n",
      "5       55876\n",
      "7       52814\n",
      "8       49618\n",
      "6       36942\n",
      "9       27505\n",
      "10       7106\n",
      "Name: open_channels, dtype: int64\n",
      "0.9383707083886137\n",
      "[0.93866, 0.9383, 0.93836, 0.93896, 0.9373]\n"
     ]
    }
   ],
   "source": [
    "np.savez_compressed('lgb_reg.npz',valid=oof_preds, test=y_preds)\n",
    "     \n",
    "f1_mean,f1_std = np.mean(cv_result),np.std(cv_result)\n",
    "print(f\"[CV] F1 Mean: {f1_mean}\")\n",
    "print(f\"[CV] F1 Std: {f1_std}\")\n",
    "\n",
    "\n",
    "# make test predictions with optimized coefficients\n",
    "sub_preds = np.round(np.clip(y_preds, 0, 10)).astype(int)\n",
    "submission['open_channels'] = sub_preds\n",
    "print(submission['open_channels'].value_counts()) \n",
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "\n",
    "print(f1_score(y,np.round(np.clip(oof_preds, 0, 10)).astype(int),average='macro'))\n",
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
